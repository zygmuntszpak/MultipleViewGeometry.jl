using ComputerVision
using Test
using StaticArrays
using GeometryTypes
using LinearAlgebra
using PGFPlotsX
using Makie
using Colors

# Generate points on two planar surfaces
xâ‚ = 0.0
xâ‚â€² = 0.0
yâ‚ = -1000.0
yâ‚â€² = 2000.0
zâ‚ = -1000.0
zâ‚â€² = 1000.0
pointsâ‚ = [Point3(rand(xâ‚:xâ‚â€²), rand(yâ‚:yâ‚â€²), rand(zâ‚:zâ‚â€²)) for n = 1:250]
planeâ‚ = [Plane(Vec3(1.0, 0.0, 0.0), 0)]
pâ‚ = [xâ‚, yâ‚, zâ‚]
qâ‚ = [xâ‚, yâ‚â€², zâ‚]
râ‚ = [xâ‚, yâ‚â€², zâ‚â€²]
sâ‚ = [xâ‚, yâ‚, zâ‚â€²]
segmentâ‚ = [pâ‚ => qâ‚ , qâ‚ => râ‚ , râ‚ => sâ‚ , sâ‚ => pâ‚]
plane_segmentâ‚ = PlaneSegment(first(planeâ‚), segmentâ‚)

xâ‚‚ = 0.0
xâ‚‚â€² = 3000.0
yâ‚‚ = 2000.0
yâ‚‚â€² = 2000.0
zâ‚‚ = -1000.0
zâ‚‚â€² = 1000.0
pointsâ‚‚ = [Point3(rand(xâ‚‚:xâ‚‚â€²), rand(yâ‚‚:yâ‚‚â€²), rand(zâ‚‚:zâ‚‚â€²)) for n = 1:250]
planeâ‚‚ = [Plane(Vec3(0.0, 1.0, 0.0), 2000)]
pâ‚‚ = [xâ‚‚, yâ‚‚, zâ‚‚]
qâ‚‚ = [xâ‚‚, yâ‚‚, zâ‚‚â€²]
râ‚‚ = [xâ‚‚â€², yâ‚‚, zâ‚‚â€²]
sâ‚‚ = [xâ‚‚â€², yâ‚‚, zâ‚‚]
segmentâ‚‚ = [pâ‚‚ => qâ‚‚ , qâ‚‚ => râ‚‚ , râ‚‚ => sâ‚‚ , sâ‚‚ => pâ‚‚]
plane_segmentâ‚‚ = PlaneSegment(first(planeâ‚‚), segmentâ‚‚)

planes = vcat(planeâ‚, planeâ‚‚)
#planes = vcat(plane_segmentâ‚, plane_segmentâ‚‚)
points = vcat(pointsâ‚, pointsâ‚‚)

groups = [IntervalAllotment(1:250), IntervalAllotment(251:500)]

world = PrimitiveWorld(points = points, planes = planes, groups = groups)

pinholeâ‚ = Pinhole(intrinsics = IntrinsicParameters(width = 640, height = 480, focal_length = 100))
analogue_imageâ‚ = AnalogueImage(coordinate_system = OpticalSystem())
cameraâ‚ = ComputerVision.Camera(image_type = analogue_imageâ‚, model = pinholeâ‚)
ğ‘â‚ = SMatrix{3,3,Float64,9}(rotxyz(90*(pi/180), -110*(pi/180), 0*(pi/180)))
ğ­â‚ = [3000.0,0.0, 0.0]
relocate!(cameraâ‚, ğ‘â‚, ğ­â‚)

pinholeâ‚‚ = Pinhole(intrinsics = IntrinsicParameters(width = 640, height = 480, focal_length = 100))
analogue_imageâ‚‚ = AnalogueImage(coordinate_system = OpticalSystem())
cameraâ‚‚ = ComputerVision.Camera(image_type = analogue_imageâ‚‚, model = pinholeâ‚‚)
ğ‘â‚‚ = SMatrix{3,3,Float64,9}(rotxyz(90*(pi/180), -110*(pi/180), 0*(pi/180)))
ğ­â‚‚ = [4000.0,0.0, 0.0]
relocate!(cameraâ‚‚, ğ‘â‚‚, ğ­â‚‚)


aquire = AquireImageContext()

# Project 3D points onto the cameras.
â„³ = aquire(world, cameraâ‚)
â„³â€² = aquire(world, cameraâ‚‚)

cameraâ‚  = deepcopy(cameraâ‚)
cameraáµ¦  = deepcopy(cameraâ‚‚)
worldâ‚‚ = deepcopy(world)

default_world_system = CartesianSystem(Point(0.0, 0.0, 0.0), Vec(1.0, 0.0, 0.0), Vec(0.0, 1.0, 0.0), Vec(0.0, 0.0, 1.0))
alternative_world_system = get_coordinate_system(get_extrinsics(get_model(cameraâ‚)))

transformation_context! = WorldCoordinateTransformationContext(CoordinateTransformation(source = default_world_system, target = alternative_world_system))
transformation_context!(cameraâ‚)
transformation_context!(cameraáµ¦)
transformation_context!(worldâ‚‚)

# Project transformed 3D points onto the cameras.
â„³â‚ = aquire(worldâ‚‚, cameraâ‚)
â„³áµ¦â€² = aquire(worldâ‚‚, cameraáµ¦)


# Verify that the coordinates of the image points are the same irrespective
# of the choice of the world coordinate system.
for couple in zip(â„³, â„³â‚)
    @test isapprox(norm(first(couple)-last(couple)), 0.0; atol = 1e-10)
end
for couple in zip(â„³â€², â„³áµ¦â€²)
    @test isapprox(norm(first(couple)-last(couple)), 0.0; atol = 1e-10)
end

# Verify that the original 3D points lie on their corresponding planes.
points3D = get_points(world)
planes3D = get_planes(world)
for (i, plane3D) in enumerate(planes3D)
    subset = points3D[get_interval(groups[i])]
    for pt in subset
        @test on_plane(pt, plane3D; tol = 1e-10)
    end
end

# Verify that the transformed 3D points lie on their corresponding transformed planes.
points3Dáµ¦ = get_points(worldâ‚‚)
planes3Dáµ¦ = get_planes(worldâ‚‚)
for (i, plane3Dáµ¦) in enumerate(planes3Dáµ¦)
    subset = points3Dáµ¦[get_interval(groups[i])]
    for pt in subset
        @test on_plane(pt, plane3Dáµ¦; tol = 1e-10)
    end
end

# Verify that the fundamental matrices are the same irrespective of how we choose
# the world coordinate system.
ğ…â‚ = matrix(FundamentalMatrix(cameraâ‚, cameraâ‚‚))
ğ…â‚ = ğ…â‚ / norm(ğ…â‚)
ğ…â‚‚ = matrix(FundamentalMatrix(cameraâ‚, cameraáµ¦))
ğ…â‚‚ = ğ…â‚‚ / norm(ğ…â‚‚)
@test norm(ğ…â‚ - ğ…â‚‚) < 1e-15


# Verify that the homography matrices are the same irrespective of how we choose
# the world coordinate system.
â„‹ = matrices(HomographyMatrices(cameraâ‚, cameraâ‚‚, get_planes(world)))
ğ‡â‚ = â„‹[1] / norm(â„‹[1])
ğ‡â‚‚ = â„‹[2] / norm(â„‹[2])

â„‹â‚‚ = matrices(HomographyMatrices(cameraâ‚, cameraáµ¦, get_planes(worldâ‚‚)))
ğ‡â‚ = â„‹â‚‚[1] / norm(â„‹â‚‚[1])
ğ‡áµ¦ = â„‹â‚‚[2] / norm(â„‹â‚‚[2])

@test norm(ğ‡â‚ .- ğ‡â‚) < 1e-15
@test norm(ğ‡â‚‚ .- ğ‡áµ¦) < 1e-15

# Verify that the points are triangulated correctly for both choices of
# world coordinate systems.
ğ’â‚ = Correspondences((â„³,â„³â€²))
triangulate_points =  TriangulateContext(DirectLinearTriangulation())
estimated_pointsâ‚ = triangulate_points(cameraâ‚, cameraâ‚‚, ğ’â‚)
# Verify that the triangulated points are close to the true points.
for couple in zip(estimated_pointsâ‚, get_points(world))
    @test isapprox(norm(first(couple)-last(couple)), 0.0; atol = 1e-7)
end

ğ’â‚‚ = Correspondences((â„³â‚,â„³áµ¦â€²))
triangulate_points =  TriangulateContext(DirectLinearTriangulation())
estimated_pointsâ‚‚ = triangulate_points(cameraâ‚, cameraáµ¦, ğ’â‚‚)
# Verify that the triangulated points are close to the true points.
for couple in zip(estimated_pointsâ‚‚, get_points(worldâ‚‚))
    @test isapprox(norm(first(couple)-last(couple)), 0.0; atol = 1e-7)
end

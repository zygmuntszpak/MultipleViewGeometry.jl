using MultipleViewGeometry, Test, Random
using MultipleViewGeometry.ModuleCostFunction
using MultipleViewGeometry.ModuleTypes
using MultipleViewGeometry.ModuleConstraints
using MultipleViewGeometry.ModuleConstruct
using LinearAlgebra
using StaticArrays

# Fix random seed.
Random.seed!(1234)


ğ’³ = [Point3D(x,y,rand(50:100)) for x = -100:5:100 for y = -100:5:100]
ğ’³ = ğ’³[1:50:end]


# Specify the coordinate systems of the world, the camera frame and the picture
# plane.
world_basis = (Vec(1.0, 0.0, 0.0), Vec(0.0, 1.0, 0.0), Vec(0.0, 0.0, 1.0))
camera_basis = (Point(0.0, 0.0, 0.0), Vec(-1.0, 0.0, 0.0), Vec(0.0, -1.0, 0.0), Vec(0.0, 0.0, 1.0))
picture_basis = (Point(0.0, 0.0), Vec(-1.0, 0.0), Vec(0.0, -1.0))

# The focal length for both cameras is one.
f = 1
image_width = 640 / 10
image_height = 480 / 10

cameraâ‚ = Pinhole(image_width, image_height, f, camera_basis..., picture_basis...)
cameraâ‚‚ = Pinhole(image_width, image_height, f, camera_basis..., picture_basis...)

# Rotate and translate camera one.
ğ‘â‚ = Matrix{Float64}(I,3,3)
ğ­â‚ = [-50.0, -2.0, 0.0]
relocate!(cameraâ‚, ğ‘â‚, ğ­â‚)

# Rotate and translate camera two.
ğ‘â‚‚ = Matrix{Float64}(I,3,3)
ğ­â‚‚ = [50.0, 2.0, 0.0]
relocate!(cameraâ‚‚, ğ‘â‚‚, ğ­â‚‚)


ğ‘â‚â€², ğ­â‚â€² = ascertain_pose(cameraâ‚, world_basis... )
ğŠâ‚â€² = obtain_intrinsics(cameraâ‚, CartesianSystem())
ğ‘â‚‚â€², ğ­â‚‚â€² = ascertain_pose(cameraâ‚‚, world_basis... )
ğŠâ‚‚â€² = obtain_intrinsics(cameraâ‚‚, CartesianSystem())

# Camera projection matrices.
ğâ‚ = construct(ProjectionMatrix(),ğŠâ‚â€²,ğ‘â‚â€²,ğ­â‚â€²)
ğâ‚‚ = construct(ProjectionMatrix(),ğŠâ‚‚â€²,ğ‘â‚‚â€²,ğ­â‚‚â€²)


# Set of corresponding points.
â„³ = project(cameraâ‚,ğâ‚,ğ’³)
â„³Ê¹ = project(cameraâ‚‚,ğâ‚‚,ğ’³)

ğ’´ = triangulate(DirectLinearTransform(),ğâ‚,ğâ‚‚,(â„³,â„³Ê¹))

# Triangulating with the same projection matrices that were used to construct
# (â„³,â„³Ê¹) should yield the same 3D points as the original ğ’³.
N = length(ğ’´)
for n = 1:N
    @test  isapprox(sum(abs.(ğ’³[n]-ğ’´[n])/3), 0.0; atol = 1e-11)
end


ğ… = construct(FundamentalMatrix(),ğŠâ‚â€²,ğ‘â‚â€²,-ğ­â‚â€²,ğŠâ‚‚â€²,ğ‘â‚‚â€²,-ğ­â‚‚â€²)

# To triangulate the corresponding points using the Fundamental matrix, we first
# have to factorise the Fundamental matrix into a pair of Camera matrices. Due
# to projective ambiguity, the camera matrices are not unique, and so the
# triangulated 3D points will most probably not match the original 3D points.
# However, when working with noiseless data, the projections of the triangulated
# points should satisfy the epipolar constraint. We can use this fact to
# validate that the triangulation is correctly implemented.
ğ’´ = triangulate(DirectLinearTransform(),ğ…,(â„³,â„³Ê¹))

ğâ‚, ğâ‚‚ = construct(ProjectionMatrix(),ğ…)
# Because we constructed the projection matrices from the fundamental matrix we
# don't know the intrinsics or extrinsics of the camera.
# The current API requires us to construct a CameraModel type for the `project`
# function. TODO: Need to revisit this.
cameraâ‚ = Pinhole(image_width, image_height, f, camera_basis..., picture_basis...)
cameraâ‚‚ = Pinhole(image_width, image_height, f, camera_basis..., picture_basis...)
ğ’ª = project(cameraâ‚,ğâ‚,ğ’´)
ğ’ªÊ¹= project(cameraâ‚‚,ğâ‚‚,ğ’´)
N = length(ğ’ª)
for n = 1:N
    ğ¦ = hom(ğ’ª[n])
    ğ¦Ê¹ = hom(ğ’ªÊ¹[n])
    @test  isapprox(ğ¦'*ğ…*ğ¦Ê¹, 0.0; atol = 1e-12)
end
